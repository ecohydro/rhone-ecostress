{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xa\n",
    "from pathlib import Path\n",
    "import src.data.ecostress_io as eio\n",
    "import rioxarray\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_partitions = 8\n",
    "root_path = Path(\"/mnt/ecostress/rhone-ecostress-data/\")\n",
    "tempdir = Path(\"/home/ryan/work/tmp-inst\")\n",
    "\n",
    "with open(f\"{root_path}/geo-countries/archive/countries.geojson\", \"rb\") as f:\n",
    "    all_countries_geojson = json.loads(f.read())\n",
    "\n",
    "\n",
    "for i in all_countries_geojson['features']:\n",
    "    if i['properties']['ADMIN'] == \"France\":\n",
    "        france_geo = i\n",
    "\n",
    "del all_countries_geojson\n",
    "\n",
    "france_gdf = gpd.GeoDataFrame.from_features([france_geo]).explode()\n",
    "\n",
    "france_gdf[france_gdf.area==max(france_gdf.area)].plot()\n",
    "\n",
    "aoi = france_gdf[france_gdf.area==max(france_gdf.area)]\n",
    "\n",
    "xmin, ymin, xmax, ymax = aoi.total_bounds\n",
    "bounds_tuple = (4, 42, 7, 47)\n",
    "xmin, ymin, xmax, ymax = bounds_tuple  # hardcoding since concattenating 1000s of ecostress files with different overlaps hangs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global rivers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_df = gpd.read_file(Path(root_path, \"europe_rivers/eu_river.shp\"))\n",
    "\n",
    "rivers_df['R_ID'] = rivers_df['R_ID'].apply(int).apply(str)\n",
    "\n",
    "france_rivers_df = rivers_df.cx[xmin:xmax, ymin:ymax]\n",
    "\n",
    "aoi.crs = france_rivers_df.crs # setting crs for aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to make sure they overlay, we subset by the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = aoi.plot(color=\"grey\", edgecolor=\"black\")\n",
    "\n",
    "france_rivers_df.plot(ax=base, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading in paths and example data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_path = Path(root_path, \"ECO3ANCQA\")\n",
    "et_path = Path(root_path, \"ECO3ETPTJPL\")\n",
    "esi_path = Path(root_path, \"ECO4ESIPTJPL\")\n",
    "\n",
    "whole_tif_qa_paths, csv_qa_paths, xml_qa_paths = eio.separate_extensions(qa_path)\n",
    "\n",
    "whole_tif_etdaily_paths, csv_et_paths, xml_et_paths = eio.separate_extensions(et_path, \"*ETinst_*.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clipping all et tifs, takes about 10 min with threading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_scene_paths = [Path(p) for p in tempdir.glob(\"*clipped*\")]\n",
    "resampled_scene_paths = [Path(p) for p in tempdir.glob(\"*resampled*\")]\n",
    "\n",
    "if clipped_scene_paths == [] and resampled_scene_paths == []:\n",
    "    client = Client()\n",
    "    \n",
    "    batches = eio.batches_from(whole_tif_etdaily_paths, 8)\n",
    "    \n",
    "    batch_results = []\n",
    "    \n",
    "    for batch in batches:\n",
    "    \n",
    "        batch_result = dask.delayed(eio.clip_and_save)(batch, bounds_tuple, filter_nan = True, outDir=tempdir)\n",
    "        batch_results.append(batch_result)\n",
    "        \n",
    "    result_futures = client.compute(batch_results, scheduler='processes')\n",
    "\n",
    "    clipped_scene_batches = [i.result() for i in result_futures]# gets rid of None that denotes too little scene overlap\n",
    "    clipped_scene_paths = []\n",
    "    for batch in clipped_scene_batches:\n",
    "        for path in batch:\n",
    "            if path != None:\n",
    "                clipped_scene_paths.append(Path(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "france_river_lines = france_rivers_df.copy()\n",
    "buffered_france_rivers_df = france_rivers_df.to_crs(epsg=2154)\\\n",
    "                                            .buffer(5000)\\\n",
    "                                            .to_crs(epsg=4326) # buffers by 5000 meters\n",
    "france_rivers_df['geometry'] = buffered_france_rivers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = eio.read_ecostress_scene(whole_tif_etdaily_paths[0]).rio.resolution()\n",
    "crs = france_rivers_df.crs\n",
    "aoi_grid = eio.gdf_to_dataarray(france_rivers_df, crs, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resampled_scene_paths == []:\n",
    "    client = Client()\n",
    "    batches = eio.batches_from(clipped_scene_paths, n_partitions)\n",
    "\n",
    "    def wrapper(paths, aoi_grid, tempdir, path_id):\n",
    "        return_paths = []\n",
    "        for path in paths:\n",
    "            with eio.read_mask_ecostress_scene(path) as x:\n",
    "                y = eio.resample_xarray_to_basis(x, aoi_grid)\n",
    "                return_paths.append(eio.write_tmp(y, tempdir, path_id))\n",
    "        return return_paths\n",
    "\n",
    "    all_results = []\n",
    "    for batch in batches:\n",
    "        sub_result = dask.delayed(wrapper)(batch, aoi_grid, tempdir, \"resampled\")\n",
    "        all_results.append(sub_result)\n",
    "\n",
    "    result_future = client.compute(all_results, scheduler=\"processes\")\n",
    "\n",
    "    resampled_scene_batches = [i.result() for i in result_future]\n",
    "    resampled_scene_paths = []\n",
    "    for batch in resampled_scene_batches:\n",
    "        for path in batch:\n",
    "            if path != None:\n",
    "                resampled_scene_paths.append(Path(path))\n",
    "    client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_arrays = eio.read_scenes(resampled_scene_paths, chunks = {\"band\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_tseries = xa.concat(resampled_data_arrays, dim=\"date\").sortby('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocube.api.core import make_geocube\n",
    "france_rivers_df['value'] = 1 # makes non empty dataset, required for resampling\n",
    "river_arr = make_geocube(vector_data=france_rivers_df, resolution=resolution)['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_path = Path(root_path, \"era5-download.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_dataset = xa.open_dataset(reanalysis_path, chunks = {\"time\": 1, \"latitude\": 39, \"longitude\": 41})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_dataset['vpd'] = eio.vapor_deficit(met_dataset['t2m']-273.15,met_dataset['d2m']-273.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_dataset = met_dataset.rio.set_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpd = met_dataset['vpd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to reduce hourly vpd before reprojecting because too much memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "local time in utc is 1 hour behind paris, so I take the mean of vpd over 10am-3pm local time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytime_mask = np.isin(vpd.time.dt.hour, [9, 10, 11, 12, 13, 14])\n",
    "\n",
    "daytime_vpd = vpd.isel(time=daytime_mask)\n",
    "\n",
    "daytime_vpd_daily = daytime_vpd.resample(time=\"1D\").mean()\n",
    "\n",
    "daytime_vpd_daily = daytime_vpd_daily.rio.set_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need this much mem to reproject..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float32(1).itemsize * np.prod([395, 6101, 6558]) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.enums import Resampling\n",
    "import os\n",
    "dataset_filename = \"Daily_VPD_10am-3pm_Paris_Time_Resampled.nc\"\n",
    "dataset_name = dataset_filename.split(\".\")[0]\n",
    "resampled_vpd_path = os.path.join(root_path, dataset_filename)\n",
    "\n",
    "if os.path.isfile(resampled_vpd_path):\n",
    "    \n",
    "    resampled_vpd_ds = xa.open_dataset(resampled_vpd_path, chunks = {\"time\": 1, \"y\": 6101, \"x\": 6558})\n",
    "    resampled_vpd_da = resampled_vpd_ds[dataset_name]\n",
    "else:\n",
    "    # this takes a long time and takes lots of mem, 64gb!\n",
    "\n",
    "    resampled_vpd_da = daytime_vpd_daily.rio.reproject_match(et_tseries[0], resampling = Resampling.bilinear)\n",
    "\n",
    "    resampled_vpd.name = dataset_name\n",
    "    \n",
    "    eio.write_netcdf(resampled_vpd_da, resampled_vpd_path)\n",
    "    \n",
    "    del resampled_vpd_da\n",
    "    \n",
    "    resampled_vpd_ds = xa.open_dataset(resampled_vpd_path, chunks = {\"time\": 1, \"y\": 6101, \"x\": 6558})\n",
    "    resampled_vpd_da = resampled_vpd_ds[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to merge ET arrays taken on same date together to reduce time coord duplicates that occur because of partial scene overlaps and large aoi. nanmean should replace nans with a true value, 2 or more true values with the mean for that day (should only happena t the overlaps, infrequently), and all nan slices with nan.\n",
    "\n",
    "Below I'm working on joining vpd and et by time and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_tseries = et_tseries.rename({'date':'time'})\n",
    "\n",
    "et_tseries_ds = et_tseries.to_dataset().sel(band=1)\n",
    "\n",
    "et_tseries_ds['time'] = et_tseries_ds['time'].values.astype('datetime64[D]')\n",
    "\n",
    "duplicated_mask = pd.to_datetime(np.array(et_tseries_ds['time'])).duplicated(keep=False)\n",
    "\n",
    "duplicate_dates = np.unique(et_tseries_ds.isel(time=duplicated_mask)['time'])\n",
    "\n",
    "duplicated_da = et_tseries_ds.isel(time=duplicated_mask).sel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_xarr_list = []\n",
    "for duplicate in duplicate_dates:\n",
    "    date = pd.to_datetime(duplicate).strftime(\"%Y-%m-%d\")\n",
    "    arr = et_tseries.sel(time=date)\n",
    "    arr = arr.where(arr != -1e+13) \n",
    "    duplicate_mean = arr.mean(dim=\"time\")\n",
    "    duplicate_mean = duplicate_mean.assign_coords({'time': duplicate})\n",
    "    duplicate_xarr_list.append(duplicate_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_duplicate_xarr = xa.concat(duplicate_xarr_list, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_tseries_ds.attrs['units'] = \"W/m^2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_tseries_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_tseries_ds_dups = et_tseries_ds.isel(time=duplicated_mask).rename({\"ECO3ETPTJPL001_EVAPOTRANSPIRATION_PT_JPL_ETinst_doy2018233132423_aid0001-clipped-resampled.tif\":\"ECO3ETPTJPL\"})\n",
    "\n",
    "et_tseries_ds_no_dups = et_tseries_ds.isel(time=~duplicated_mask).rename({\"ECO3ETPTJPL001_EVAPOTRANSPIRATION_PT_JPL_ETinst_doy2018233132423_aid0001-clipped-resampled.tif\":\"ECO3ETPTJPL\"}) # gettign rid of duplicates in original et xarr\n",
    "\n",
    "et_tseries_ds_dups=et_tseries_ds_dups.where(et_tseries_ds_dups[\"ECO3ETPTJPL\"] != -1e+13) \n",
    "\n",
    "et_tseries_ds_no_dups=et_tseries_ds_no_dups.where(et_tseries_ds_no_dups[\"ECO3ETPTJPL\"] != -1e+13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_duplicate_dataset = mean_duplicate_xarr.to_dataset().sel(band=1).rename({\"ECO3ETPTJPL001_EVAPOTRANSPIRATION_PT_JPL_ETinst_doy2018233132423_aid0001-clipped-resampled.tif\":\"ECO3ETPTJPL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_vpd_ds = xa.concat([et_tseries_ds_no_dups, mean_duplicate_dataset], dim=\"time\").sortby(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling why there are edge effects between ET Daily Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dates = [pd.to_datetime(date).strftime(\"%Y-%m-%d\") for date in duplicate_dates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_arrays[0]['date'].dt.month.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in whole_tif_etdaily_paths:\n",
    "    if \"2018222\" in str(path):\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_arrays_profile = []\n",
    "for da in resampled_data_arrays:\n",
    "    if str(da.date.dt.month.values) == \"8\" and str(da.date.dt.year.values) == \"2018\" and str(da.date.dt.day.values) == \"10\":\n",
    "        resampled_data_arrays_profile.append(da.where(da!=-1e+13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_arrays_profile[0][0].plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_arrays_profile[1][0].plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_arrays_profile[-1][0].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantaeous uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_uncertainty_paths = [\"/mnt/ecostress/rhone-ecostress-data/ECO3ETPTJPL/ECO3ETPTJPL.001_EVAPOTRANSPIRATION_PT_JPL_ETinstUncertainty_doy2018222131552_aid0001.tif\",\n",
    "\"/mnt/ecostress/rhone-ecostress-data/ECO3ETPTJPL/ECO3ETPTJPL.001_EVAPOTRANSPIRATION_PT_JPL_ETinstUncertainty_doy2018222180613_aid0001.tif\",\n",
    "\"/mnt/ecostress/rhone-ecostress-data/ECO3ETPTJPL/ECO3ETPTJPL.001_EVAPOTRANSPIRATION_PT_JPL_ETinstUncertainty_doy2018222180704_aid0001.tif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_uncertainty_paths = [Path(path) for path in inst_uncertainty_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_uncertainty_paths = eio.clip_and_save(inst_uncertainty_paths, bounds_tuple, filter_nan = True, outDir=Path('/home/ryan/work/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_scenes = eio.read_scenes([Path(path) for path in clipped_uncertainty_paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_scenes[0][0].attrs['units'] = \"W/m^2\"\n",
    "uncertainty_scenes[0][0].plot.imshow(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_scenes[1][0].plot.imshow(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_scenes[2][0].plot.imshow(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms where scenes intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_plot = duplicate_dates[1]\n",
    "n_scenes = len(et_tseries_ds_dups.sel(time=date_to_plot)['time'])\n",
    "data_to_plot = et_tseries_ds_dups[\"ECO3ETPTJPL\"].sel(time=date_to_plot).drop(\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_intersect_data = data_to_plot.where((data_to_plot[0] > 0) & (data_to_plot[1] > 0) & (data_to_plot[2] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "xa.plot.hist(valid_intersect_data[0],ax=ax, alpha=.6, bins = 25)\n",
    "xa.plot.hist(valid_intersect_data[1],ax=ax, alpha=.6, bins = 25)\n",
    "xa.plot.hist(valid_intersect_data[2],ax=ax, alpha=.6, bins = 25)\n",
    "plt.title(\"Instantaneous ET Disagreement between the intersection of 3 Ecostress scenes on August 10, 2018, France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot['time'] = [0, 1, 2]\n",
    "data_to_plot.attrs['units'] = \"W/m^2\"\n",
    "data_to_plot.plot.imshow(x='x', y='y', col='time', col_wrap=n_scenes, robust=True, figsize=(20,8))\n",
    "# plt.title(f\"{n_scenes} individual scenes for date {date_to_plot}\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1)\n",
    "date_to_plot = duplicate_dates[1]\n",
    "et_vpd_ds[\"ECO3ETPTJPL\"].sel(time=date_to_plot).plot.imshow(ax=ax)\n",
    "f.set_size_inches(18.5, 10.5)\n",
    "n_scenes = len(et_tseries_ds_dups.sel(time=date_to_plot)['time'])\n",
    "plt.title(f\"{n_scenes} scenes for date {date_to_plot}, mean taken at overlaps\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting ecostress availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_tseries = et_tseries.sel(band=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_2018_may_sept=et_tseries.sel(date=slice(\"2018-06-01\", \"2018-09-30\"))\n",
    "\n",
    "et_2018_may_sept=et_2018_may_sept.chunk(chunks={\"date\": 101, \"y\": 1000, \"x\": 1000})\n",
    "\n",
    "et_2018_may_sept = et_2018_may_sept.where(et_2018_may_sept > 0)\n",
    "\n",
    "et_nonnan_count = ~np.isnan(et_2018_may_sept)\n",
    "\n",
    "true_count = et_nonnan_count.astype(bool).sum(dim=\"date\")\n",
    "\n",
    "true_count_c = true_count.compute()\n",
    "\n",
    "f, ax = plt.subplots(1)\n",
    "true_count_c.plot.imshow(ax=ax)\n",
    "plt.title(\"Number of ECOSTRESS Observations, May-Sept 2018\")\n",
    "france_river_lines.plot(ax=ax, color=\"red\")\n",
    "f.set_size_inches(18.5, 10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating hourly data to dekad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pev_dekad = met_dataset['pev'].resample(time='1D').sum().resample(time='10D').mean()\n",
    "\n",
    "pev_dekad_2018 = pev_dekad.sel(time=slice(\"2018-01-01\", \"2018-10-01\"))\n",
    "\n",
    "met_dataset['pev'].sel(time=\"2019-04-01\")\n",
    "\n",
    "pev_dekad_2019.plot(x='longitude', y='latitude', col='time', col_wrap=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretty ET plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ETcolors = [\"#f6e8c3\", \"#d8b365\", \"#99974a\", \"#53792d\", \"#6bdfd2\", \"#1839c5\"]\n",
    "ETcmap = LinearSegmentedColormap.from_list(\"ET\", ETcolors)\n",
    "date_utc = pd.to_datetime(et['date'].values)\n",
    "layer_type = et.attrs['filename'].split(\"_\")[-3]\n",
    "title = 'ECO3ETPTJPL Evapotranspiration'\n",
    "\n",
    "fig = plt.figure(figsize=(9.7,7.6))                                                       # Set the figure size (x,y)\n",
    "fig.suptitle(f'{title} ({layer_type}) \\n at {date_utc}', fontsize=22)  # Add title for the plots\n",
    "plt.axis('off')                                                                           # Remove axes from plot\n",
    "im = plt.imshow(et.sel(band=1), cmap=ETcmap);                                                        # Plot array using colormap\n",
    "# plt.scatter(Tcol, Trow, color=\"black\", marker='x')                                        # Plot tower location\n",
    "# Add a colormap legend\n",
    "plt.colorbar(im, orientation='horizontal', fraction=0.05, pad=0.004, label=f\"ET ({et.attrs['units']})\", shrink=0.6).outline.set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code graveyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to plot xarray image data and geopandas data with ipyleaflet but it can't do image overlays yet (unless it comes from a server via url potentially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet as ipyl\n",
    "x = france_river_lines.unary_union.envelope.centroid.xy[0][0]\n",
    "y = france_river_lines.unary_union.envelope.centroid.xy[1][0]\n",
    "e, n, w, s =true_count_c.rio.bounds()\n",
    "m = ipyl.Map(center = (y,x), zoom=6)\n",
    "\n",
    "rivers_data = ipyl.GeoData(geo_dataframe = france_river_lines,\n",
    "                   style={'color': 'purple', 'opacity':3, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.6},\n",
    "                   hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "                   name = 'Rivers')\n",
    "m.add_layer(rivers_data)\n",
    "plt.imsave(\"observation_count.jpeg\",true_count_c)\n",
    "obs_heatmap = ipyl.ImageOverlay(\n",
    "    url=\"observation_count.jpeg\",\n",
    "    bounds=((s, w), (n, e))\n",
    ")\n",
    "\n",
    "m.add_layer(obs_heatmap)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to plot ecostress DataArray with geopandas shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartopy_project_geo_df(df, crs):\n",
    "\n",
    "    # This can be converted into a `proj4` string/dict compatible with GeoPandas\n",
    "    crs_proj4 = crs.proj4_init\n",
    "    return df.to_crs(crs_proj4)\n",
    "\n",
    "crs = ccrs.PlateCarree()\n",
    "aoi_projected = cartopy_project_geo_df(aoi, crs)\n",
    "france_rivers_df_projected = cartopy_project_geo_df(france_rivers_df, crs)\n",
    "# base = aoi_projected.plot(color=\"grey\", edgecolor=\"black\")\n",
    "# france_rivers_df_projected.plot(ax=base, color=\"blue\")\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.axes(projection=crs)\n",
    "all_et_daily[14].sel(band=1).plot.imshow(ax=ax, transform=crs)\n",
    "# ax.add_geometries(aoi_projected['geometry'], crs=crs)\n",
    "ax.add_geometries(france_rivers_df_projected['geometry'], crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_NA_values():\n",
    "    \"\"\"\n",
    "    Daily ET products have both nan values from where there are clouds \n",
    "    and -1e+13 for where the ecostress swath was clipped during the ordering process\n",
    "    \"\"\"\n",
    "    masked_et = np.ma.masked_where(et.sel(band=1) == np.nan, et.sel(band=1))\n",
    "    masked_et = np.ma.masked_where(masked_et == -1e+13, masked_et)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
