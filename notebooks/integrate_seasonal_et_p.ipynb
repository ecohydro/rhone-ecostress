{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from rasterio.enums import Resampling\n",
    "%matplotlib inline\n",
    "\n",
    "all_scenes_f_precip = Path('/scratch/waves/rhone-ecostress/rasters/chirps-clipped')\n",
    "all_scenes_f_et = Path('/home/serdp/rhone/rhone-ecostress/rasters/eeflux/PDR')\n",
    "\n",
    "all_precip_paths = list(all_scenes_f_precip.glob(\"*\"))\n",
    "all_pdr_et_paths = list(all_scenes_f_et.glob(\"*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason the fll value is not correct. this is the correct bad value to mask by\n",
    "testf = all_precip_paths[0]\n",
    "x = rio.open_rasterio(testf)\n",
    "badvalue = np.unique(x.where(x != x._FillValue).sel(band=1))[0]\n",
    "\n",
    "def chirps_path_date(path):\n",
    "    _, _, year, month, day, _ = path.name.split(\".\")\n",
    "    day = day.split(\"-\")[0]\n",
    "    return datetime(int(year), int(month), int(day))\n",
    "\n",
    "\n",
    "def open_chirps(path):\n",
    "    data_array = rio.open_rasterio(path) #chunks makes i lazyily executed\n",
    "    data_array = data_array.sel(band=1).drop(\"band\") # gets rid of old coordinate dimension since we need bands to have unique coord ids\n",
    "    data_array[\"date\"] = chirps_path_date(path) # makes a new coordinate\n",
    "    return data_array.expand_dims({\"date\":1}) # makes this coordinate a dimension\n",
    "\n",
    "\n",
    "\n",
    "### data is not tiled so not a good idea to use chunking\n",
    "#https://github.com/pydata/xarray/issues/2314\n",
    "\n",
    "import rasterio\n",
    "with rasterio.open(testf) as src:\n",
    "    print(src.profile)\n",
    "\n",
    "len(all_precip_paths) * 41.7 / 10e3\n",
    "\n",
    "%timeit open_chirps(testf)\n",
    "\n",
    "all_daily_precip_path = \"/home/serdp/ravery/rhone-ecostress/netcdfs/all_chirps_daily.nc\"\n",
    "\n",
    "if Path(all_daily_precip_path).exists():\n",
    "    \n",
    "    all_chirps_arr = xr.open_dataarray(all_daily_precip_path)\n",
    "    all_chirps_arr = all_chirps_arr.sortby(\"date\")\n",
    "else:\n",
    "\n",
    "    daily_chirps_arrs = []\n",
    "\n",
    "    for path in all_precip_paths:\n",
    "\n",
    "        daily_chirps_arrs.append(open_chirps(path)) \n",
    "        \n",
    "    all_chirps_arr = xr.concat(daily_chirps_arrs, dim=\"date\")\n",
    "    \n",
    "    all_chirps_arr = all_chirps_arr.sortby(\"date\")\n",
    "\n",
    "    all_chirps_arr.to_netcdf(all_daily_precip_path)\n",
    "\n",
    "def eeflux_path_date(path):\n",
    "    year, month, day, _ = path.name.split(\"_\")\n",
    "    return datetime(int(year), int(month), int(day))\n",
    "\n",
    "def open_eeflux(path, da_for_match):\n",
    "    data_array = rio.open_rasterio(path) #chunks makes i lazyily executed\n",
    "    data_array.rio.reproject_match(da_for_match)\n",
    "    data_array = data_array.sel(band=1).drop(\"band\") # gets rid of old coordinate dimension since we need bands to have unique coord ids\n",
    "    data_array[\"date\"] = eeflux_path_date(path) # makes a new coordinate\n",
    "    return data_array.expand_dims({\"date\":1}) # makes this coordinate a dimension\n",
    "\n",
    "da_for_match = rio.open_rasterio(all_pdr_et_paths[0])\n",
    "daily_eeflux_arrs = [open_eeflux(path, da_for_match) for path in all_pdr_et_paths]\n",
    "all_eeflux_arr = xr.concat(daily_eeflux_arrs, dim=\"date\")\n",
    "all_daily_eeflux_path = \"/home/serdp/ravery/rhone-ecostress/netcdfs/all_eeflux_daily.nc\"\n",
    "all_eeflux_arr.to_netcdf(all_daily_eeflux_path)\n",
    "\n",
    "all_eeflux_arr[-3,:,:].plot.imshow()\n",
    "\n",
    "all_eeflux_arr = all_eeflux_arr.sortby(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_list(all_eeflux_arr):\n",
    "    ey = max(all_eeflux_arr['date.year'].values)\n",
    "    sy = min(all_eeflux_arr['date.year'].values)\n",
    "    start_years = range(sy,ey)\n",
    "    end_years = range(sy+1, ey+1)\n",
    "    return list(zip(start_year,end_year))\n",
    "\n",
    "def group_by_custom_doy(all_eeflux_arr, doy_start, doy_end):\n",
    "    start_end_years = years_list(all_eeflux_arr)\n",
    "    water_year_arrs = []\n",
    "    for water_year in start_end_years:\n",
    "        start_mask = ((all_eeflux_arr['date.dayofyear'].values > doy_start) & (all_eeflux_arr['date.year'].values == water_year[0]))\n",
    "        end_mask = ((all_eeflux_arr['date.dayofyear'].values < doy_end) & (all_eeflux_arr['date.year'].values == water_year[1]))\n",
    "        water_year_arrs.append(all_eeflux_arr[start_mask | end_mask])\n",
    "    return water_year_arrs\n",
    "doystart = 275\n",
    "doyend = 125\n",
    "water_year_arrs = group_by_custom_doy(all_eeflux_arr, doystart, doyend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = list(map(lambda x: len(x['date']), water_year_arrs))\n",
    "year_tuples = years_list(all_eeflux_arr)\n",
    "\n",
    "indexes = np.arange(len(year_tuples))\n",
    "plt.bar(indexes, group_counts)\n",
    "degrees = 80\n",
    "plt.xticks(indexes, year_tuples, rotation=degrees, ha=\"center\")\n",
    "plt.title(\"Availability of EEFLUX between DOY 275 and 125\")\n",
    "plt.savefig(\"eeflux_availability.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_seasonal_precip(precip_arr, eeflux_group_arr):\n",
    "    return precip_arr.sel(date=slice(eeflux_group_arr.date.min(), eeflux_group_arr.date.max())).sum(dim=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, eeflux_group in enumerate(water_year_arrs):\n",
    "    if len(eeflux_group['date']) > 0:\n",
    "        seasonal_precip = sum_seasonal_precip(all_chirps_arr, eeflux_group)\n",
    "        seasonal_et = eeflux_group.integrate(dim=\"date\", datetime_unit=\"D\")\n",
    "        year_range = year_tuples[index]\n",
    "        pname = f\"seasonal_chirps_{year_range[0]}_{year_range[1]}_{doystart}_{doyend}.tif\"\n",
    "        eename = f\"seasonal_eeflux_integrated_{year_range[0]}_{year_range[1]}_{doystart}_{doyend}.tif\"\n",
    "        seasonal_precip.rio.to_raster(pname)\n",
    "        seasonal_et.rio.to_raster(eename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_year_arrs[0][0].plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_year_arrs[0].integrate(dim=\"date\", datetime_unit=\"D\").plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eeflux_arr.groupby(????????).integrate(dim=\"date\", datetime_unit=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "labels = ['<=2', '3-9', '>=10']\n",
    "bins = [0,2,9, np.inf]\n",
    "pd.cut(all_eeflux_arr, bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eeflux_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_scene_ids = [str(i) for i in list(all_scenes_f.glob(\"L*\"))]\n",
    "df = pd.DataFrame({\"scene_id\":all_scene_ids}).reindex()\n",
    "split_vals_series = df.scene_id.str.split(\"/\")\n",
    "\n",
    "dff = pd.DataFrame(split_vals_series.to_list(), columns=['_', '__', '___', '____', '_____', '______', 'fname'])\n",
    "\n",
    "df['date'] = dff['fname'].str.slice(10,18)\n",
    "\n",
    "df['pathrow'] = dff['fname'].str.slice(4,10)\n",
    "\n",
    "df['sensor'] = dff['fname'].str.slice(0,4)\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df = df.set_index(\"datetime\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marc_df = df['2014-01-01':'2019-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marc_df = marc_df[marc_df['sensor']==\"LC08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x.where(x != badvalue).sel(band=1).plot.imshow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
